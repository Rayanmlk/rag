#  RAG Portfolio â€” SystÃ¨me de Question-RÃ©ponse sur Papers IA/ML

> SystÃ¨me RAG (Retrieval-Augmented Generation) spÃ©cialisÃ© sur des papers scientifiques IA/ML.
> **DiffÃ©renciateur clÃ©** : comparaison rigoureuse de 3 modÃ¨les d'embeddings avec mÃ©triques RAGAS.

![CI](https://github.com/Rayanmlk/rag-portfolio/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green)
![ChromaDB](https://img.shields.io/badge/ChromaDB-0.4-orange)

## ğŸ¯ Ce que fait ce projet

Pose une question sur les Transformers, BERT, GPT-3, ou les systÃ¨mes RAG â†’ l'API rÃ©cupÃ¨re les passages pertinents dans une base vectorielle de papers et gÃ©nÃ¨re une rÃ©ponse sourcÃ©e et vÃ©rifiable.

**Ce qui le distingue d'un simple chatbot** : le systÃ¨me Ã©value et compare 3 modÃ¨les d'embeddings diffÃ©rents avec 4 mÃ©triques objectives (Faithfulness, Answer Relevancy, Context Precision, Context Recall).

## ğŸ—ï¸ Architecture

```
Question utilisateur
        â†“
[Embedding Engine] â†’ encode la question en vecteur
        â†“
[ChromaDB VectorStore] â†’ recherche les K passages les plus similaires
        â†“
[LLM Client] â†’ gÃ©nÃ¨re une rÃ©ponse Ã  partir des passages (Mistral/OpenAI)
        â†“
RÃ©ponse sourcÃ©e + mÃ©triques temps rÃ©el
```

```
rag-portfolio/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py          # API FastAPI (ask, index, evaluate, models, stats)
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ pipeline.py      # RAGPipeline, EmbeddingEngine, VectorStore, LLMClient
â”‚   â””â”€â”€ data.py          # Documents de dÃ©mo (papers IA/ML) + QA pairs
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ metrics.py       # RAGEvaluator + ModelComparator
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_all.py      # Tests unitaires et d'intÃ©gration
â””â”€â”€ .github/workflows/
    â””â”€â”€ ci.yml           # Tests â†’ Ã‰valuation RAG â†’ Deploy
```

## âš¡ DÃ©marrage rapide

```bash
git clone https://github.com/TON_USERNAME/rag-portfolio
cd rag-portfolio
pip install -r requirements.txt

# Optionnel : clÃ© API pour LLM (sans clÃ© = mode dÃ©mo)
export MISTRAL_API_KEY=your_key  # ou OPENAI_API_KEY

uvicorn app.main:app --reload
# â†’ http://localhost:8000/docs
```

## ğŸ“¡ Endpoints API

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Info + modÃ¨les disponibles |
| GET | `/health` | SantÃ© + nb documents indexÃ©s |
| POST | `/ask` | **Question â†’ RÃ©ponse sourcÃ©e** |
| POST | `/index` | Indexer de nouveaux documents |
| GET | `/evaluate` | **Comparer les modÃ¨les d'embeddings** |
| GET | `/models` | DÃ©tails des modÃ¨les disponibles |
| GET | `/stats` | Stats de la base vectorielle |

### Exemple de question

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the Transformer architecture?", "n_chunks": 5}'
```

```json
{
  "answer": "The Transformer uses self-attention mechanisms without recurrence...",
  "sources": ["Vaswani et al., 2017 â€” arXiv:1706.03762"],
  "similarity_scores": [0.87, 0.82, 0.79],
  "retrieval_time_ms": 12.4,
  "embedding_model": "minilm"
}
```

## ğŸ”¬ Comparaison des modÃ¨les d'embeddings

```bash
GET /evaluate?models=minilm,mpnet&n_questions=5
```

```json
{
  "avg_scores": {
    "minilm": 0.6234,
    "mpnet":  0.7012
  },
  "best_model": "mpnet",
  "interpretation": {
    "best_model": "mpnet est le meilleur modÃ¨le pour ce corpus"
  }
}
```

**4 mÃ©triques Ã©valuÃ©es :**
- **Faithfulness** (30%) â€” la rÃ©ponse s'appuie-t-elle sur les sources ?
- **Answer Relevancy** (30%) â€” la rÃ©ponse rÃ©pond-elle Ã  la question ?
- **Context Precision** (20%) â€” les passages rÃ©cupÃ©rÃ©s sont-ils pertinents ?
- **Context Recall** (20%) â€” les passages contiennent-ils l'information nÃ©cessaire ?

## ğŸ§  ModÃ¨les d'embeddings comparÃ©s

| ModÃ¨le | Dims | Vitesse | Usage optimal |
|--------|------|---------|---------------|
| `minilm` | 384 | âš¡ Rapide | Prototypage, faible latence |
| `mpnet` | 768 | ğŸ”„ Moyen | Production gÃ©nÃ©raliste |
| `scibert` | 768 | ğŸ”„ Moyen | Textes scientifiques |

## ğŸ§ª Tests

```bash
pytest tests/ -v --cov=app --cov=rag --cov=evaluation
```

## ğŸ› ï¸ Stack

`Python` Â· `FastAPI` Â· `ChromaDB` Â· `Sentence-Transformers` Â· `Mistral AI` Â· `Docker` Â· `GitHub Actions`

## ğŸ‘¤ Auteur

**[Ton PrÃ©nom Nom]** â€” M1 Data & IA
- GitHub: [@Rayanmlk](https://github.com/TON_USERNAME)
- Demo: [API live](https://rag-portfolio.railway.app/docs)
